class dnESPCN(nn.Module):
    def __init__(self, upscale_factor= 4):
        super(dnESPCN, self).__init__()
        self.name = 'dnESPCN'
        self.upfactor = upscale_factor

        self.a_index = np.array([[3, 2, 2, 3],[2, 1, 1, 2],[2, 1, 1, 2],[3, 2, 2, 3]])
        self.relu = nn.ReLU()

        self.lrconvs_1 = self.make_layer(sESPCN_block, 3)

        self.conv_res = nn.Conv2d(3, 3*(upscale_factor**2), 5, stride=1, padding=2)
        self.conv_first_2 = nn.Conv2d(3, 64, 5, stride=1, padding=2)
        self.lrconvs_2 = self.make_layer(Conv_ReLU_Block, 2)
        self.conv_last_2_1 = nn.Conv2d(64, 3 * 4, 1, padding=0)  
        self.conv_last_2_2 = nn.Conv2d(64, 3 * 8, 3, padding=1)
        self.conv_last_2_3 = nn.Conv2d(64, 3 * 4, 5, padding=2)

        self.conv_prep_2 = nn.Conv2d(3, 64, 5, stride=1, padding=2)
        self.hrconvs = self.make_layer(Conv_ReLU_Block, 2)
        self.conv_prep_3 = nn.Conv2d(64, 3, 3, stride=1, padding=1)

        self.pixel_shuffle_r = nn.PixelShuffle(upscale_factor)
        self.pixel_shuffle_g = nn.PixelShuffle(upscale_factor)
        self.pixel_shuffle_b = nn.PixelShuffle(upscale_factor)

        # xavier initialization
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))

    def make_layer(self, block, num_of_layer):
        layers = []
        for _ in range(num_of_layer):
            layers.append(block())
        return nn.Sequential(*layers)

    def forward(self, x):
        # Denoise
        x = self.lrconvs_1(x)
        lr = x

        #Upscale
        res = self.conv_res(x)
        x = self.relu(self.conv_first_2(x))
        x = self.lrconvs_2(x)
        x1 = self.conv_last_2_1(x)
        x2 = self.conv_last_2_2(x)
        x3 = self.conv_last_2_3(x)
        cnt1 = 0
        cnt2 = 0
        cnt3 = 0
        for j in range(3):
            for i in np.nditer(self.a_index):
                if cnt3 == 0: # for the first index
                    x = x3[:,0,:,:].unsqueeze(1)
                    cnt3 += 1
                    continue
                if i == 3.0:
                    x = torch.cat((x, x3[:, cnt3, :, :].unsqueeze(1)), 1)
                    cnt3 += 1
                if i == 2.0:
                    x = torch.cat((x, x2[:, cnt2, :, :].unsqueeze(1)), 1)
                    cnt2 += 1
                if i == 1.0:
                    x = torch.cat((x, x1[:, cnt1, :, :].unsqueeze(1)), 1)
                    cnt1 += 1
        x = x + res
        r = self.pixel_shuffle_r(x[:, 0:(self.upfactor ** 2), :, :])
        g = self.pixel_shuffle_g(x[:, (self.upfactor ** 2):2 * (self.upfactor ** 2), :, :])
        b = self.pixel_shuffle_b(x[:, 2 * (self.upfactor ** 2):3 * (self.upfactor ** 2), :, :])
        x = torch.cat((r,g,b), 1)

        # HR finetuning
        res = x
        x = self.relu(self.conv_prep_2(x))
        x = self.hrconvs(x)
        x = self.conv_prep_3(x)
        x = x + res

        return x, lr
